# BitBot

**Local Real-Time AI Assistant with Speech-to-Text, Large Language Model, and Text-to-Speech Integration**

> âš ï¸ **Development Notice**: This project is currently under active development and is primarily intended for learning and educational purposes. Features may be incomplete, unstable, or subject to significant changes. This is an experimental project to explore local AI assistant architecture and implementation.

## Overview

BitBot is a local, real-time, audio-enabled AI assistant designed to run entirely on consumer hardware without requiring cloud services or internet connectivity for core functionality. The project implements a streaming STT â†’ LLM â†’ TTS pipeline with wake word detection, optimized for responsive conversational interactions on daily-driver laptops and desktop computers.

## ğŸš€ Quick Start

### Current Development Status

**MVP Status**: ğŸ”§ **In Active Development**
- âœ… Core architecture implemented
- âœ… Simplified TTS engine working
- âœ… Text chat interface ready
- âœ… Component integration designed
- ğŸ”§ Dependency installation needed
- ğŸ”§ Model management in progress

### Prerequisites

1. **Python 3.8+** with pip
2. **Ollama** for local LLM serving (future)
3. **Porcupine Access Key** for wake word detection (future)

### Installation

1. **Clone and navigate to project:**
   ```bash
   git clone <repository-url>
   cd bitbot
   ```

2. **Install core dependencies:**
   ```bash
   pip install -r requirements-core.txt
   ```

3. **Test the architecture:**
   ```bash
   python test_mvp.py
   ```

4. **Try the text chat interface:**
   ```bash
   python main.py chat
   ```

### Development Setup (Advanced)

1. **Install Ollama (for LLM integration):**
   ```bash
   # Download from https://ollama.com/
   ollama pull mistral:7b-instruct
   ollama serve
   ```

2. **Get Porcupine access key (for wake word):**
   - Visit https://console.picovoice.ai/
   - Create account and get access key
   - Copy `.env.example` to `.env` and add your key:
   ```bash
   cp .env.example .env
   # Edit .env and add your PORCUPINE_ACCESS_KEY
   ```

3. **Test full setup:**
   ```bash
   python main.py test
   ```

4. **Start BitBot (when ready):**
   ```bash
   python main.py start
   ```

## ğŸ™ï¸ Usage

### Text Chat Mode (Available Now)
```bash
python main.py chat
```
- Interactive text conversation with BitBot
- Rich terminal interface with commands
- Conversation history and status

### Voice Chat Mode (NEW!)
```bash
python main.py start --nowake
```
- **Direct conversation mode** - no wake word needed
- **Clean chat interface** - production-ready experience
- **Turn-based conversation** - BitBot waits for you to finish speaking
- **Voice input/output** - speak naturally and get audio responses

### Traditional Voice Mode (Wake Word)
```bash
python main.py start
```
- **Wake BitBot:** Say "Hey BitBot"
- **Talk naturally:** BitBot processes speech and responds
- **End conversation:** Say "goodbye" or "bye"

## ğŸ“‹ Current Commands

### Available Commands
```bash
python main.py chat                    # Start text chat interface
python main.py start                   # Start voice assistant with wake word
python main.py start --nowake          # Start direct voice chat (no wake word)
python main.py start --debug           # Start with debug logging
python main.py config                  # Show current configuration
python main.py test                    # Test all components (when ready)
python main.py setup                   # Show setup guide
python main.py version                 # Show version info
```

### Development Commands
```bash
python test_mvp.py                     # Test architecture without dependencies
```

## âš™ï¸ Configuration

BitBot automatically detects your hardware and configures accordingly:

### Hardware Tiers

- **BitBotS (Small)**: Standard PCs, older laptops
  - STT: Whisper tiny.en
  - LLM: Mistral 7B (Q4_K_M)
  - TTS: Simple pyttsx3

- **BitBotM (Medium)**: Modern laptops, 4GB+ VRAM
  - STT: Whisper small.en
  - LLM: Llama 3.1 8B (Q4_K_M)
  - TTS: Simple pyttsx3 + gTTS

- **BitBotL (Large)**: High-end PCs, 8GB+ VRAM
  - STT: Whisper large-v3
  - LLM: Llama 3.1 8B (Q5_K_M)
  - TTS: Simple pyttsx3 + gTTS

### Environment Variables

Edit `.env` file to customize:

```bash
# Required (for voice mode)
PORCUPINE_ACCESS_KEY=your_key_here

# Optional
OLLAMA_BASE_URL=http://localhost:11434
AUDIO_INPUT_DEVICE=0
AUDIO_OUTPUT_DEVICE=0
LOG_LEVEL=INFO
```

## ğŸ—ï¸ Architecture

### System Architecture:

<img width="1219" height="895" alt="image" src="https://github.com/user-attachments/assets/374b150d-aa48-4385-8a4a-f1c800e67e6d" />

### Core Components

- **Audio Manager**: Cross-platform audio I/O with sounddevice
- **STT Engine**: Faster Whisper for speech recognition
- **LLM Engine**: Ollama client with OpenAI-compatible API
- **TTS Engine**: Simple pyttsx3-based synthesis (MVP)
- **Wake Word**: Picovoice Porcupine for trigger detection
- **Pipeline**: Asyncio orchestration of STT â†’ LLM â†’ TTS
- **Chat Interface**: Rich text-based interaction

### Data Flow:

<img width="1644" height="620" alt="image" src="https://github.com/user-attachments/assets/39d134a6-c494-4932-b392-8e212d79ad3b" />


### Web Search:

<img width="346" height="1224" alt="image" src="https://github.com/user-attachments/assets/57d75ba1-8bce-4757-a72e-6b51a117f7d6" />

## ğŸ› ï¸ Development

### Project Structure

```
bitbot/
â”œâ”€â”€ audio/             # Audio I/O management
â”œâ”€â”€ cli/               # Command-line interfaces  
â”œâ”€â”€ config/            # Configuration management
â”œâ”€â”€ core/              # Pipeline orchestration
â”œâ”€â”€ llm/               # LLM integration
â”œâ”€â”€ stt/               # Speech-to-text engines
â”œâ”€â”€ tts/               # Text-to-speech engines
â”‚   â”œâ”€â”€ simple_engine.py    # MVP TTS (current)
â”‚   â””â”€â”€ realtime_engine.py  # Advanced TTS (future)
â”œâ”€â”€ wake_word/         # Wake word detection
â””â”€â”€ __init__.py
main.py                # CLI entry point
test_mvp.py           # Architecture tests
requirements-core.txt  # Core dependencies (MVP)
requirements.txt      # Full dependencies (future)
```

### Development Status

See [DEVELOPMENT_STATUS.md](DEVELOPMENT_STATUS.md) for detailed progress tracking.

### Git Branching Strategy

- `main` - Production-ready releases
- `develop` - Integration branch for features
- `feature/*` - Individual component development
- `release/*` - Release preparation

### Key Technologies

- **Python asyncio**: Non-blocking I/O and pipeline orchestration
- **Faster Whisper**: High-performance STT inference
- **Ollama**: Local LLM deployment platform
- **pyttsx3**: Cross-platform text-to-speech (MVP)
- **sounddevice**: Cross-platform audio handling
- **Rich**: Beautiful terminal interfaces

## ğŸš¨ Troubleshooting

### Common Issues

1. **Architecture test failures:**
   ```bash
   pip install psutil loguru
   python test_mvp.py
   ```

2. **Missing dependencies:**
   ```bash
   pip install -r requirements-core.txt
   ```

3. **Ollama not running (future):**
   ```bash
   ollama serve
   ```

4. **Audio device issues (future):**
   ```bash
   python main.py test  # Check audio devices
   ```

### Getting Help

Check detailed documentation:
- [Development Status](DEVELOPMENT_STATUS.md) - Current progress
- [MVP Development Plan](MVP_DEVELOPMENT_PLAN.md) - Complete roadmap

## ğŸ¯ Current MVP Status

### âœ… Working Features
- âœ… Text chat interface with rich formatting
- âœ… LLM integration architecture
- âœ… Configuration system with hardware tiers
- âœ… Modular component design
- âœ… Async pipeline orchestration
- âœ… CLI commands and help system

### ğŸ”§ In Development
- ğŸ”§ Model downloading and management
- ğŸ”§ Audio pipeline optimization
- ğŸ”§ Integration testing
- ğŸ”§ Dependency resolution completion

### ğŸ“‹ Coming Soon
- Web search integration
- Wake word detection integration
- Speech-to-text processing
- Text-to-speech synthesis
- End-to-end voice pipeline
- Performance optimization

## ğŸ”® Roadmap

### Next Release (v0.1.0 - MVP)
- [ ] Web search integration
- [ ] Complete dependency installation
- [ ] Model management system
- [ ] End-to-end voice pipeline
- [ ] Integration testing
- [ ] Performance optimization

### Future Releases
- **v0.2.0**: Advanced TTS, web interface, custom wake words
- **v0.3.0**: MCP integration, RAG, multi-language
- **v1.0.0**: Production deployment, enterprise features

## ğŸ“„ License

MIT License - see LICENSE file for details.

## ğŸ¤ Contributing

This project is in active development. See [DEVELOPMENT_STATUS.md](DEVELOPMENT_STATUS.md) for current priorities and how to contribute.

---

**BitBot**: Your local AI assistant, private by design. ğŸ¤–

*Current Status: MVP in development with core architecture complete*
